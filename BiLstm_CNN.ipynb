{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BiLstm CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvBVf4g3v6vk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBTQpJjuCw76"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout, LSTM, Conv2D, Bidirectional, Dense, MaxPooling2D, MaxPooling3D, Reshape, Flatten, TimeDistributed\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isy9ZiflxoPc",
        "outputId": "7c5d7c00-3868-4e29-d979-c9951c0763b8"
      },
      "source": [
        "# # Assume that you have 12GB of GPU memory and want to allocate ~4GB:\n",
        "# tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
        "\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# for gpu in gpus:\n",
        "#   tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
        "  try:\n",
        "    tf.config.set_logical_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.LogicalDeviceConfiguration(memory_limit=6000)])\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Virtual devices must be set before GPUs have been initialized\n",
        "    print(e)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a01smi7hDPqH",
        "outputId": "824990c6-c37a-4fae-c057-b6893319d7ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qdcazp6DU01"
      },
      "source": [
        "#Global Variables\n",
        "IMG_SIZE = 100\n",
        "OPTIMIZER = 'SGD'\n",
        "LEARNING_RATE = 0.01\n",
        "DECAY = 1e-6\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 5\n",
        "LOSS = CategoricalCrossentropy()\n",
        "NUM_FRAMES = 10\n",
        "KERNEL = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR0tmngODaGa"
      },
      "source": [
        "OUTPUTFILEPATH =\"./Hockeyfights/\"\n",
        " \n",
        "violenceIndicator ='fi'\n",
        "nonViolenceIndicator = 'no'\n",
        " \n",
        "if not os.path.exists(OUTPUTFILEPATH):\n",
        "    os.mkdir(OUTPUTFILEPATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85zbZY1DDdXr"
      },
      "source": [
        "#Video Frame Extraction\n",
        "def extractFrames(folder):\n",
        " \n",
        "    if os.path.exists(folder) == False:\n",
        "        print(str(folder) + \" not found\")\n",
        "        return;\n",
        " \n",
        "    c =0\n",
        "    for files in tqdm(os.listdir(folder)):\n",
        "        path = os.path.join(folder, files)\n",
        "        cap = cv2.VideoCapture(path)\n",
        " \n",
        "        success = True\n",
        " \n",
        "        while success:\n",
        "            success, image = cap.read()\n",
        " \n",
        "            # RGB_img =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "            RGB_img = image\n",
        " \n",
        "            if not success:\n",
        "                break\n",
        " \n",
        "            if (violenceIndicator in files):\n",
        "                if not os.path.exists(OUTPUTFILEPATH + \"/\" + violenceIndicator):\n",
        "                    os.mkdir(OUTPUTFILEPATH + \"/\" + violenceIndicator +\"/\")\n",
        " \n",
        "                cv2.resize(cv2.imwrite(OUTPUTFILEPATH + \"/\" + violenceIndicator+ \"/\"+ str(c) + '.jpg', RGB_img), (IMG_SIZE, IMG_SIZE))\n",
        "            else:\n",
        "                if not os.path.exists(OUTPUTFILEPATH + \"/\" + nonViolenceIndicator):\n",
        "                    os.mkdir(OUTPUTFILEPATH + \"/\" + nonViolenceIndicator +\"/\")\n",
        "                    \n",
        "                cv2.resize(cv2.imwrite(OUTPUTFILEPATH + \"/\" + nonViolenceIndicator+ \"/\"+ str(c) + '.jpg', RGB_img), (IMG_SIZE, IMG_SIZE))\n",
        " \n",
        "            c +=1\n",
        "    print(c)\n",
        "    print(\"Done with file extraction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq0PluwBD0f8"
      },
      "source": [
        "#dataset generation\n",
        "def GenerateDataset():\n",
        "    dataset = []\n",
        "    images = []\n",
        "    limit = 0\n",
        "    \n",
        "    violenceFilePath = OUTPUTFILEPATH + violenceIndicator +\"/\"\n",
        "    nonViolenceFilePath = OUTPUTFILEPATH + nonViolenceIndicator + \"/\"\n",
        " \n",
        "    for frames in tqdm(os.listdir(violenceFilePath)):\n",
        "        path = os.path.join(violenceFilePath, frames)\n",
        "        img = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
        " \n",
        "        images.append(np.array(img))\n",
        "        limit +=1\n",
        "    \n",
        " \n",
        "        if limit == NUM_FRAMES:\n",
        "            limit = 0\n",
        "            dataset.append(np.array([images, np.array([0, 1])]))\n",
        "            images = []\n",
        " \n",
        "    for frames in tqdm(os.listdir(nonViolenceFilePath)):\n",
        "        path = os.path.join(nonViolenceFilePath, frames)\n",
        "        img = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
        " \n",
        "        images.append(np.array(img))\n",
        "        limit +=1\n",
        "    \n",
        " \n",
        "        if limit == NUM_FRAMES:\n",
        "            limit = 0\n",
        "            dataset.append(np.array([images, np.array([1, 0])]))\n",
        "            images = []\n",
        " \n",
        " \n",
        "    print(\"Dataset Count \" + str(len(dataset)))\n",
        "    shuffle(dataset)\n",
        "    np.save('datasetCNN.npy', dataset)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6GafHGeD4do",
        "outputId": "99c10f5b-b9dc-4824-941a-6950b1a6a4e6"
      },
      "source": [
        "#Assign Extracted Data\n",
        "\n",
        "#__Extract frames from data____\n",
        "#extractFrames(\"./drive/MyDrive/NewTrainHockey\")\n",
        "#extractFrames(\"./drive/MyDrive/HockeyDataset\")\n",
        "extractFrames(\"./drive/MyDrive/HockeyFights\")\n",
        "\n",
        "data = GenerateDataset()\n",
        "\n",
        "#Uncomment if data has been extracted\n",
        "#data = np.load('datasetCNN.npy', allow_pickle=True)\n",
        "\n",
        "#print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/MyDrive/HockeyDataset not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1012/1012 [12:34<00:00,  1.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "41548\n",
            "Done with file extraction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20926 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "100%|██████████| 20926/20926 [00:36<00:00, 575.84it/s]\n",
            "  0%|          | 0/20622 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "100%|██████████| 20622/20622 [00:36<00:00, 568.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset Count 4154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ktHklmD8q8"
      },
      "source": [
        "train, test = train_test_split(data, train_size=0.7, shuffle=True)\n",
        "\n",
        "# print(train[0][1])\n",
        "# print(train[1][1])\n",
        "\n",
        "\n",
        "X = np.array([i[0] for i in train]).reshape(-1, NUM_FRAMES, IMG_SIZE, IMG_SIZE, 3)\n",
        "y = np.array([i[1] for i in train])\n",
        "\n",
        "x_valid = np.array([i[0] for i in test]).reshape(-1, NUM_FRAMES, IMG_SIZE, IMG_SIZE, 3)\n",
        "y_valid = np.array([i[1] for i in test])\n",
        "\n",
        "X = X.astype('float32')\n",
        "x_valid = x_valid.astype('float32')\n",
        "\n",
        "X /= 255\n",
        "x_valid /=255\n",
        "\n",
        "#print(X)\n",
        "print(\"Training sample size = \" +str(len(X)))\n",
        "print(\"Testing sample size = \" +str(len(x_valid)))\n",
        "print(x_valid.shape)\n",
        "# print(y[0])\n",
        "# print(len(y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEH_W7qOEBsX"
      },
      "source": [
        "num = 110\n",
        "visible_frame = X[num]\n",
        "visible_frame =  np.array(visible_frame).reshape(10,100,100,3)\n",
        " \n",
        "plt.imshow(visible_frame[7])\n",
        "print(y[num])\n",
        "#print(np.array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gBVPa1rrUuj"
      },
      "source": [
        "#clear up memory\n",
        "del data\n",
        "#del visible_frame\n",
        "#del num\n",
        "del train\n",
        "del test\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjm53AcrEHhy"
      },
      "source": [
        "#Architecture of Model\n",
        "\n",
        "model = Sequential()\n",
        "#input\n",
        "model.add(Conv2D(KERNEL, (3, 3), activation='relu',  input_shape = (NUM_FRAMES, IMG_SIZE, IMG_SIZE, 3), padding ='same'))\n",
        "\n",
        "#____v_____\n",
        "model.add(Conv2D(KERNEL, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D((1,2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#____v_____\n",
        "model.add(Conv2D(KERNEL, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D((1,2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#____v_____\n",
        "model.add(Conv2D(KERNEL, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D((1,2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#___V____\n",
        "#model.add(Flatten())\n",
        "model.add(Reshape((NUM_FRAMES, KERNEL * IMG_SIZE)));\n",
        "\n",
        "#____V_____________\n",
        "lstmForward = LSTM(units=32)\n",
        "lstmBackward = LSTM(units=32, go_backwards=True)\n",
        "model.add(Bidirectional(lstmForward, backward_layer= lstmBackward))\n",
        "\n",
        "\n",
        "#________V_________\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "#model.add(Dense(32, activation='sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(Dense(2, activation='softmax'))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og-hvZi8gjTC"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_aDgI8af1nU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBSj6whSFFsq"
      },
      "source": [
        "#Model Training\n",
        "\n",
        "model.compile(loss= LOSS, optimizer= SGD(LEARNING_RATE), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs= EPOCHS, verbose=1, validation_data=(x_valid,y_valid))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8uFFl4akn2U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kITi4m5eFPZ5"
      },
      "source": [
        "model.save(\"SavedFirst/BiLstMNet.h5\");\n",
        "print(\"Saved Model\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1GvIu5l5h4e"
      },
      "source": [
        "score = model.evaluate(x_valid, y_valid, verbose =0)\n",
        "print('Test loss', score[0])\n",
        "print('Test accuracy', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-VzaauRFJFn"
      },
      "source": [
        "history_dict = history.history;\n",
        "\n",
        "loss_value = history_dict['loss'];\n",
        "val_loss_value = history_dict['val_loss'];\n",
        "epoch = range(1,len(loss_value) + 1);\n",
        "\n",
        "line1 =plt.plot(epoch, val_loss_value, label=\"Validation/Test loss\");\n",
        "line2 =plt.plot(epoch, loss_value, label=\"Training loss\");\n",
        "\n",
        "plt.setp(line1, linewidth=2.0, marker ='+', markersize = 10.0);\n",
        "plt.setp(line2, linewidth=2.0, marker ='4', markersize = 10.0);\n",
        "\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Loss');\n",
        "plt.grid(True);\n",
        "plt.legend()\n",
        "\n",
        "plt.show();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkaPHsqmFMqF"
      },
      "source": [
        "history_dict = history.history;\n",
        "\n",
        "acc_value = history_dict['accuracy'];\n",
        "val_acc_value = history_dict['val_accuracy'];\n",
        "epoch = range(1,len(acc_value) + 1);\n",
        "\n",
        "line1 =plt.plot(epoch, val_acc_value, label=\"Validation/Test accuracy\");\n",
        "line2 =plt.plot(epoch, acc_value, label=\"Training accuracy\");\n",
        "\n",
        "plt.setp(line1, linewidth=2.0, marker ='+', markersize = 10.0);\n",
        "plt.setp(line2, linewidth=2.0, marker ='4', markersize = 10.0);\n",
        "\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Accuracy');\n",
        "plt.grid(True);\n",
        "plt.legend()\n",
        "\n",
        "plt.show();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0n04GGDFXXK"
      },
      "source": [
        "classifier = load_model(\"SavedFirst/BiLstMNet.h5\")\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "score = classifier.evaluate(x_valid, y_valid, verbose =0)\n",
        "\n",
        "print('Test loss', score[0])\n",
        "print('Test accuracy', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDjxTMaRFejO"
      },
      "source": [
        "def showModelTest(input_value, prediction):\n",
        "  print(\"Prediction= \" + str(prediction))\n",
        "  if (prediction[0][0] > prediction[0][1]):\n",
        "    print(\"No violence here\")\n",
        "  else:\n",
        "    print(\"Violence Present\")\n",
        "  plt.imshow(input_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0usbS6RqFiAU"
      },
      "source": [
        "rand = np.random.randint(0, len(x_valid))\n",
        "input_v = x_valid[rand]\n",
        "#print(input_v.shape)\n",
        "\n",
        "input_v = input_v[0].reshape(100,100,3)\n",
        "\n",
        "#print(x_valid[rand].shape)\n",
        "#print(x_valid.shape);\n",
        "val = x_valid[rand].reshape(1,10,100,100,3)\n",
        "\n",
        "result = classifier.predict_classes(val, 1,  verbose = 0)\n",
        "\n",
        "#print(result)\n",
        "\n",
        "showModelTest(input_v, result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}